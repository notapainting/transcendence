Using bundled JDK: /usr/share/logstash/jdk
Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties
[2024-06-17T14:30:03,097][WARN ][deprecation.logstash.runner] NOTICE: Running Logstash as superuser is not recommended and won't be allowed in the future. Set 'allow_superuser' to 'false' to avoid startup errors in future releases.
[2024-06-17T14:30:03,105][INFO ][logstash.runner          ] Log4j configuration path used is: /usr/share/logstash/config/log4j2.properties
[2024-06-17T14:30:03,107][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"8.14.1", "jruby.version"=>"jruby 9.4.7.0 (3.1.4) 2024-04-29 597ff08ac1 OpenJDK 64-Bit Server VM 17.0.11+9 on 17.0.11+9 +indy +jit [x86_64-linux]"}
[2024-06-17T14:30:03,108][INFO ][logstash.runner          ] JVM bootstrap flags: [-Xms1g, -Xmx1g, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djruby.compile.invokedynamic=true, -XX:+HeapDumpOnOutOfMemoryError, -Djava.security.egd=file:/dev/urandom, -Dlog4j2.isThreadContextMapInheritable=true, -Dlogstash.jackson.stream-read-constraints.max-string-length=200000000, -Dlogstash.jackson.stream-read-constraints.max-number-length=10000, -Dls.cgroup.cpuacct.path.override=/, -Dls.cgroup.cpu.path.override=/, -Djruby.regexp.interruptible=true, -Djdk.io.File.enableADS=true, --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED, --add-opens=java.base/java.security=ALL-UNNAMED, --add-opens=java.base/java.io=ALL-UNNAMED, --add-opens=java.base/java.nio.channels=ALL-UNNAMED, --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, --add-opens=java.management/sun.management=ALL-UNNAMED, -Dio.netty.allocator.maxOrder=11]
[2024-06-17T14:30:03,109][INFO ][logstash.runner          ] Jackson default value override `logstash.jackson.stream-read-constraints.max-string-length` configured to `200000000`
[2024-06-17T14:30:03,109][INFO ][logstash.runner          ] Jackson default value override `logstash.jackson.stream-read-constraints.max-number-length` configured to `10000`
[2024-06-17T14:30:03,113][INFO ][logstash.settings        ] Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
[2024-06-17T14:30:03,114][INFO ][logstash.settings        ] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
[2024-06-17T14:30:03,271][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2024-06-17T14:30:03,276][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"84add0b3-ba2d-49d2-a19d-28692e9f4304", :path=>"/usr/share/logstash/data/uuid"}
[2024-06-17T14:30:03,737][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600, :ssl_enabled=>false}
[2024-06-17T14:30:04,205][INFO ][org.reflections.Reflections] Reflections took 104 ms to scan 1 urls, producing 132 keys and 468 values
[2024-06-17T14:30:04,649][INFO ][logstash.javapipeline    ] Pipeline `main` is configured with `pipeline.ecs_compatibility: v8` setting. All plugins in this pipeline will default to `ecs_compatibility => v8` unless explicitly configured otherwise.
[2024-06-17T14:30:04,659][INFO ][logstash.outputs.elasticsearch][main] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["https://es01:9200"]}
[2024-06-17T14:30:04,816][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[https://elastic:xxxxxx@es01:9200/]}}
[2024-06-17T14:30:05,040][WARN ][logstash.outputs.elasticsearch][main] Restored connection to ES instance {:url=>"https://elastic:xxxxxx@es01:9200/"}
[2024-06-17T14:30:05,040][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch version determined (8.14.1) {:es_version=>8}
[2024-06-17T14:30:05,040][WARN ][logstash.outputs.elasticsearch][main] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>8}
[2024-06-17T14:30:05,048][INFO ][logstash.outputs.elasticsearch][main] Not eligible for data streams because config contains one or more settings that are not compatible with data streams: {"template"=>"/etc/logstash/logstash.json", "template_overwrite"=>"true", "ilm_enabled"=>"true", "ilm_pattern"=>"000001", "template_name"=>"logstash_template", "ilm_rollover_alias"=>"logstash-index", "manage_template"=>"true", "ilm_policy"=>"logstash_policy"}
[2024-06-17T14:30:05,048][INFO ][logstash.outputs.elasticsearch][main] Data streams auto configuration (`data_stream => auto` or unset) resolved to `false`
[2024-06-17T14:30:05,050][INFO ][logstash.outputs.elasticsearch][main] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["https://es01:9200"]}
[2024-06-17T14:30:05,067][INFO ][logstash.outputs.elasticsearch][main] Using mapping template from {:path=>"/etc/logstash/logstash.json"}
[2024-06-17T14:30:05,069][INFO ][logstash.outputs.elasticsearch][main] Overwriting index lifecycle name and rollover alias as ILM is enabled
[2024-06-17T14:30:05,084][INFO ][logstash.outputs.elasticsearch][main] Installing Elasticsearch template {:name=>"logstash_template"}
[2024-06-17T14:30:05,199][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[https://elastic:xxxxxx@es01:9200/]}}
[2024-06-17T14:30:05,227][WARN ][logstash.outputs.elasticsearch][main] Restored connection to ES instance {:url=>"https://elastic:xxxxxx@es01:9200/"}
[2024-06-17T14:30:05,228][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch version determined (8.14.1) {:es_version=>8}
[2024-06-17T14:30:05,229][WARN ][logstash.outputs.elasticsearch][main] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>8}
[2024-06-17T14:30:05,236][INFO ][logstash.outputs.elasticsearch][main] Not eligible for data streams because config contains one or more settings that are not compatible with data streams: {"template"=>"/etc/logstash/nginx.json", "template_overwrite"=>"true", "ilm_enabled"=>"true", "ilm_pattern"=>"000001", "template_name"=>"nginx_template", "ilm_rollover_alias"=>"nginx-index", "manage_template"=>"true", "ilm_policy"=>"nginx_policy"}
[2024-06-17T14:30:05,236][INFO ][logstash.outputs.elasticsearch][main] Data streams auto configuration (`data_stream => auto` or unset) resolved to `false`
[2024-06-17T14:30:05,237][WARN ][logstash.filters.grok    ][main] ECS v8 support is a preview of the unreleased ECS v8, and uses the v1 patterns. When Version 8 of the Elastic Common Schema becomes available, this plugin will need to be updated
[2024-06-17T14:30:05,248][INFO ][logstash.outputs.elasticsearch][main] Using mapping template from {:path=>"/etc/logstash/nginx.json"}
[2024-06-17T14:30:05,254][INFO ][logstash.outputs.elasticsearch][main] Overwriting index lifecycle name and rollover alias as ILM is enabled
[2024-06-17T14:30:05,265][INFO ][logstash.outputs.elasticsearch][main] Installing Elasticsearch template {:name=>"nginx_template"}
[2024-06-17T14:30:05,339][WARN ][logstash.filters.grok    ][main] ECS v8 support is a preview of the unreleased ECS v8, and uses the v1 patterns. When Version 8 of the Elastic Common Schema becomes available, this plugin will need to be updated
[2024-06-17T14:30:06,256][INFO ][logstash.outputs.elasticsearch][main] Created rollover alias {:name=>"<logstash-index-000001>"}
[2024-06-17T14:30:06,371][INFO ][logstash.outputs.elasticsearch][main] Created rollover alias {:name=>"<nginx-index-000001>"}
[2024-06-17T14:30:09,591][INFO ][logstash.geoipdatabasemanagement.manager][main] managed geoip database has been updated on disk {:database_type=>"ASN", :database_path=>"/usr/share/logstash/data/geoip_database_management/1718634605/GeoLite2-ASN.mmdb"}
[2024-06-17T14:30:09,675][INFO ][logstash.geoipdatabasemanagement.manager][main] managed geoip database has been updated on disk {:database_type=>"City", :database_path=>"/usr/share/logstash/data/geoip_database_management/1718634605/GeoLite2-City.mmdb"}
[2024-06-17T14:30:09,683][INFO ][logstash.filters.geoip.databasemanager][main] By not manually configuring a database path with `database =>`, you accepted and agreed MaxMind EULA. For more details please visit https://www.maxmind.com/en/geolite2/eula
[2024-06-17T14:30:09,683][INFO ][logstash.filters.geoip   ][main] Using geoip database {:path=>"/usr/share/logstash/data/geoip_database_management/1718634605/GeoLite2-City.mmdb"}
[2024-06-17T14:30:09,723][INFO ][logstash.javapipeline    ][main] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50, "pipeline.max_inflight"=>500, "pipeline.sources"=>["/usr/share/logstash/pipeline/logstash.conf"], :thread=>"#<Thread:0x70fa2806 /usr/share/logstash/logstash-core/lib/logstash/java_pipeline.rb:134 run>"}
[2024-06-17T14:30:10,335][INFO ][logstash.javapipeline    ][main] Pipeline Java execution initialization time {"seconds"=>0.61}
[2024-06-17T14:30:10,486][INFO ][logstash.javapipeline    ][main] Pipeline started {"pipeline.id"=>"main"}
[2024-06-17T14:30:10,487][INFO ][logstash.inputs.tcp      ][main][dc567d1434f5036a1efd86268d56704e378eb380d1b914fa3fddfeda64189606] Starting tcp input listener {:address=>"0.0.0.0:5140", :ssl_enabled=>false}
[2024-06-17T14:30:10,487][INFO ][logstash.inputs.tcp      ][main][02ca1aaacb9821792f7504a14f1953e133690fdb04443ba9d6714be24a85ee43] Starting tcp input listener {:address=>"0.0.0.0:5141", :ssl_enabled=>false}
[2024-06-17T14:30:10,501][INFO ][logstash.inputs.udp      ][main][3b225d1f8d425cbb6c05a7eaee3f3ebc70dd19f27438286e2b41b6deaee375ff] Starting UDP listener {:address=>"0.0.0.0:5141"}
[2024-06-17T14:30:10,502][INFO ][logstash.inputs.udp      ][main][88d5015b088f3427cac85c72a8b73513a728e5aa01898699666783c407ce5e15] Starting UDP listener {:address=>"0.0.0.0:5140"}
[2024-06-17T14:30:10,503][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2024-06-17T14:30:10,513][INFO ][logstash.inputs.udp      ][main][88d5015b088f3427cac85c72a8b73513a728e5aa01898699666783c407ce5e15] UDP listener started {:address=>"0.0.0.0:5140", :receive_buffer_bytes=>"106496", :queue_size=>"2000"}
[2024-06-17T14:30:10,513][INFO ][logstash.inputs.udp      ][main][3b225d1f8d425cbb6c05a7eaee3f3ebc70dd19f27438286e2b41b6deaee375ff] UDP listener started {:address=>"0.0.0.0:5141", :receive_buffer_bytes=>"106496", :queue_size=>"2000"}
